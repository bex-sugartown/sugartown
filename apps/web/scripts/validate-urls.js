#!/usr/bin/env node
/**
 * validate-urls.js â€” Dev-time URL Authority Validator
 *
 * Checks ALL published Sanity documents that require canonical URLs for:
 *   A) Duplicate canonical URLs (two docs resolving to same path)
 *   B) Published docs missing a required slug
 *
 * Also validates navigation items against canonical route patterns.
 *
 * Usage:
 *   pnpm validate:urls
 *
 * Exits with code 1 if any errors are found, 0 if clean.
 *
 * Environment variables required (reads from .env or process.env):
 *   VITE_SANITY_PROJECT_ID
 *   VITE_SANITY_DATASET
 *   VITE_SANITY_API_VERSION
 */

import { createClient } from '@sanity/client'
import { readFileSync } from 'fs'
import { resolve, dirname } from 'path'
import { fileURLToPath } from 'url'

const __dirname = dirname(fileURLToPath(import.meta.url))

// â”€â”€â”€ Load env from .env file â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function loadEnv() {
  const envPath = resolve(__dirname, '../.env')
  try {
    const raw = readFileSync(envPath, 'utf8')
    for (const line of raw.split('\n')) {
      const trimmed = line.trim()
      if (!trimmed || trimmed.startsWith('#')) continue
      const eqIdx = trimmed.indexOf('=')
      if (eqIdx === -1) continue
      const key = trimmed.slice(0, eqIdx).trim()
      const value = trimmed.slice(eqIdx + 1).trim().replace(/^["']|["']$/g, '')
      if (!process.env[key]) process.env[key] = value
    }
  } catch {
    // .env not found â€” rely on process.env (CI etc.)
  }
}

loadEnv()

// â”€â”€â”€ Route registry (inline â€” mirrors src/lib/routes.js) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Duplicated here so the script has no bundler dependency.

const TYPE_NAMESPACES = {
  post: 'articles',
  caseStudy: 'case-studies',
  node: 'nodes',
}

function getCanonicalPath({ docType, slug }) {
  if (!slug) return null
  const s = slug.replace(/^\/+|\/+$/g, '').trim()
  if (!s) return null
  if (docType === 'page') return `/${s}`
  const prefix = TYPE_NAMESPACES[docType]
  if (!prefix) return null
  return `/${prefix}/${s}`
}

const ARCHIVE_PATHS = ['/articles', '/case-studies', '/knowledge-graph', '/nodes']
const TAXONOMY_BASE_PATHS = ['/tags', '/categories', '/projects', '/people']

function validateNavItemUrl(rawUrl) {
  if (!rawUrl) return { valid: false, reason: 'url is empty/null' }
  if (rawUrl.startsWith('http://') || rawUrl.startsWith('https://')) return { valid: true }

  // Normalise trailing slash: /knowledge-graph/ â†’ /knowledge-graph
  // (except root "/" which should stay as-is)
  const url = rawUrl.length > 1 ? rawUrl.replace(/\/+$/, '') : rawUrl

  if (url !== rawUrl) {
    // Trailing slash detected â€” warn about it but still check if the normalised path is valid
    const inner = validateNavItemUrl(url)
    if (inner.valid) {
      return {
        valid: false,
        reason: `trailing slash â€” canonical path is "${url}" (update in Sanity nav)`,
      }
    }
  }

  if (url === '/') return { valid: true }
  if (ARCHIVE_PATHS.includes(url)) return { valid: true }
  if (TAXONOMY_BASE_PATHS.some((b) => url === b || url.startsWith(b + '/'))) return { valid: true }
  const namespacePrefixes = Object.values(TYPE_NAMESPACES).map((p) => `/${p}/`)
  if (namespacePrefixes.some((prefix) => url.startsWith(prefix))) return { valid: true }
  const segments = url.replace(/^\//, '').split('/')
  const reserved = [
    ...Object.values(TYPE_NAMESPACES),
    ...ARCHIVE_PATHS.map((p) => p.replace(/^\//, '')),
    ...TAXONOMY_BASE_PATHS.map((p) => p.replace(/^\//, '')),
  ]
  if (segments.length === 1 && !reserved.includes(segments[0])) return { valid: true }
  return { valid: false, reason: `"${url}" does not match any canonical route pattern` }
}

// â”€â”€â”€ Sanity client â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const projectId = process.env.VITE_SANITY_PROJECT_ID
const dataset = process.env.VITE_SANITY_DATASET ?? 'production'
const apiVersion = process.env.VITE_SANITY_API_VERSION ?? '2025-02-02'

if (!projectId) {
  console.error('[validate-urls] ERROR: VITE_SANITY_PROJECT_ID is not set.')
  process.exit(1)
}

const client = createClient({ projectId, dataset, apiVersion, useCdn: false })

// â”€â”€â”€ Fetch all slugs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const query = `{
  "pages": *[_type == "page" && defined(slug.current)] { _id, _type, title, "slug": slug.current },
  "posts": *[_type == "post" && defined(slug.current)] { _id, _type, title, "slug": slug.current },
  "caseStudies": *[_type == "caseStudy" && defined(slug.current)] { _id, _type, title, "slug": slug.current },
  "nodes": *[_type == "node" && defined(slug.current)] { _id, _type, title, "slug": slug.current },
  "archivePages": *[_type == "archivePage" && defined(slug.current)] { _id, _type, title, "slug": slug.current, contentTypes },
  "pagesNoSlug": *[_type == "page" && !defined(slug.current)] { _id, _type, title },
  "postsNoSlug": *[_type == "post" && !defined(slug.current)] { _id, _type, title },
  "caseStudiesNoSlug": *[_type == "caseStudy" && !defined(slug.current)] { _id, _type, title },
  "nodesNoSlug": *[_type == "node" && !defined(slug.current)] { _id, _type, title },
  "navItems": *[_type == "navigation"][0...10] {
    title,
    items[]{
      label,
      "url": link.url,
      children[]{
        label,
        "url": link.url
      }
    }
  }
}`

// â”€â”€â”€ Run validation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function run() {
  console.log('\nğŸ”  Sugartown URL Validator')
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n')
  console.log(`   Project: ${projectId}  |  Dataset: ${dataset}\n`)

  let data
  try {
    data = await client.fetch(query)
  } catch (err) {
    console.error('[validate-urls] Sanity fetch failed:', err.message)
    process.exit(1)
  }

  const { pages, posts, caseStudies, nodes, archivePages } = data
  const missingSlug = [
    ...data.pagesNoSlug,
    ...data.postsNoSlug,
    ...data.caseStudiesNoSlug,
    ...data.nodesNoSlug,
  ]

  // Build a set of published archive slugs for nav cross-reference
  const publishedArchiveSlugs = new Set(archivePages.map((a) => a.slug))

  // â”€â”€ A) Build canonical URL map and detect duplicates â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  const urlMap = new Map() // canonical path â†’ doc info
  const duplicates = []
  const allDocs = [
    ...pages.map((d) => ({ ...d, docType: 'page' })),
    ...posts.map((d) => ({ ...d, docType: 'post' })),
    ...caseStudies.map((d) => ({ ...d, docType: 'caseStudy' })),
    ...nodes.map((d) => ({ ...d, docType: 'node' })),
  ]

  let totalDocs = allDocs.length

  for (const doc of allDocs) {
    const path = getCanonicalPath({ docType: doc.docType, slug: doc.slug })
    if (!path) continue

    if (urlMap.has(path)) {
      duplicates.push({ path, docs: [urlMap.get(path), doc] })
    } else {
      urlMap.set(path, doc)
    }
  }

  // â”€â”€ B) Print URL Coverage Report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  console.log('ğŸ“‹  URL Coverage Report')
  console.log('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')
  console.log(`   Total docs with slugs inspected: ${totalDocs}`)
  console.log(`     pages:        ${pages.length}`)
  console.log(`     posts:        ${posts.length}`)
  console.log(`     caseStudies:  ${caseStudies.length}`)
  console.log(`     nodes:        ${nodes.length}`)
  console.log()

  console.log('ğŸ“  Published Archive Pages')
  console.log('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')
  if (archivePages.length === 0) {
    console.log('   âš ï¸   No published archivePage docs found â€” archive routes will render 404')
  } else {
    for (const ap of archivePages) {
      const hasSlashIssue = ap.slug && (ap.slug.startsWith('/') || ap.slug.endsWith('/'))
      const icon = hasSlashIssue ? 'âš ï¸ ' : 'âœ…'
      console.log(`   ${icon}  /${ap.slug}  â†’  [${(ap.contentTypes || []).join(', ')}]  "${ap.title}"`)
      if (hasSlashIssue) {
        console.log(`        â†³ Slug has leading/trailing slash â€” will not match route. Fix in Studio.`)
      }
    }
  }
  console.log()

  if (missingSlug.length === 0) {
    console.log('   âœ…  No docs with missing slugs')
  } else {
    console.log(`   âš ï¸   ${missingSlug.length} doc(s) missing required slug:`)
    for (const doc of missingSlug) {
      console.log(`        [${doc._type}] "${doc.title || 'untitled'}" â€” ${doc._id}`)
    }
  }

  console.log()

  if (duplicates.length === 0) {
    console.log('   âœ…  No duplicate canonical URLs detected')
  } else {
    console.log(`   âŒ  ${duplicates.length} duplicate canonical URL(s) detected:`)
    for (const dup of duplicates) {
      console.log(`\n        Path: ${dup.path}`)
      for (const doc of dup.docs) {
        console.log(
          `          â†’ [${doc.docType}] "${doc.title || 'untitled'}" (${doc._id})`,
        )
      }
    }
  }

  // â”€â”€ C) Print Nav Resolution Report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  console.log('\nğŸ§­  Nav Resolution Report')
  console.log('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€')

  const navWarnings = []
  const navItems = data.navItems ?? []

  if (navItems.length === 0) {
    console.log('   (no navigation documents found)')
  }

  for (const nav of navItems) {
    if (!nav.items?.length) continue
    console.log(`\n   Nav: "${nav.title || 'untitled'}"`)
    for (const item of nav.items) {
      const { valid, reason } = validateNavItemUrl(item.url)
      // Extra check: if url is an archive path, verify a published archivePage doc exists for it
      let archiveWarning = null
      if (valid && item.url) {
        const stripped = item.url.replace(/^\/|\/$/g, '')
        if (ARCHIVE_PATHS.includes(`/${stripped}`) && !publishedArchiveSlugs.has(stripped)) {
          archiveWarning = `no published archivePage doc with slug "${stripped}" â€” route will 404`
        }
      }
      const icon = (valid && !archiveWarning) ? 'âœ…' : 'âš ï¸ '
      console.log(`     ${icon}  "${item.label}" â†’ ${item.url ?? '(no url)'}`)
      if (!valid) navWarnings.push({ label: item.label, url: item.url, reason })
      if (archiveWarning) navWarnings.push({ label: item.label, url: item.url, reason: archiveWarning })

      for (const child of item.children ?? []) {
        const cv = validateNavItemUrl(child.url)
        let childArchiveWarning = null
        if (cv.valid && child.url) {
          const stripped = child.url.replace(/^\/|\/$/g, '')
          if (ARCHIVE_PATHS.includes(`/${stripped}`) && !publishedArchiveSlugs.has(stripped)) {
            childArchiveWarning = `no published archivePage doc with slug "${stripped}" â€” route will 404`
          }
        }
        const ci = (cv.valid && !childArchiveWarning) ? '  âœ…' : '  âš ï¸ '
        console.log(`       ${ci}  "${child.label}" â†’ ${child.url ?? '(no url)'}`)
        if (!cv.valid) navWarnings.push({ label: child.label, url: child.url, reason: cv.reason })
        if (childArchiveWarning) navWarnings.push({ label: child.label, url: child.url, reason: childArchiveWarning })
      }
    }
  }

  // â”€â”€ D) Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  console.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')
  const errors = duplicates.length
  const warnings = missingSlug.length + navWarnings.length

  if (errors === 0 && warnings === 0) {
    console.log('âœ…  All checks passed â€” URL authority is clean.\n')
    process.exit(0)
  }

  if (errors > 0) {
    console.log(`âŒ  ${errors} ERROR(S) found â€” duplicate canonical URLs must be resolved.`)
  }
  if (warnings > 0) {
    console.log(`âš ï¸   ${warnings} WARNING(S) found â€” review missing slugs and nav items.`)
  }
  console.log()

  process.exit(errors > 0 ? 1 : 0)
}

run()
